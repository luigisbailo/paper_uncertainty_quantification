{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c0eba7-7e59-4988-9f2d-3595f0fb8d17",
   "metadata": {},
   "source": [
    "# Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7477b-3560-4977-b4c9-dcf8443aa96a",
   "metadata": {},
   "source": [
    "---\n",
    "### Supplementary material to reproduce results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfb5fd-48c8-40ad-93b5-3097f539e84f",
   "metadata": {},
   "source": [
    "In this notebook, we reproduce the results presented in the paper 'Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space' submitted to the conference NeurIPS 2023. To reproduce results, all cells must be activated from top to bottom. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff377d-0715-42dc-8063-b0db7b096b39",
   "metadata": {},
   "source": [
    "We import some packages that are required to be installed in the local environment where the notebook is run. Some classes and functions used in the notebook are defined in the modules 'nn' and 'confidence_eval'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508daf35-8def-45a5-b16f-94adfe0ac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from confidence_eval import (\n",
    "    get_confidence_ensemble,\n",
    "    get_confidence_inference,\n",
    "    get_confidence_mcdropout,\n",
    "    get_percentiles_inference,\n",
    ")\n",
    "from nn import Classifier, train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272719d-89c5-4180-81eb-107e5d1246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3f763-aef9-4e28-9a39-318d29c9b0b7",
   "metadata": {},
   "source": [
    "First of all, we download the MNIST dataset. Data is then rearranged in a dictionary, classified by their label as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a5849-4e00-474b-8278-2af735b82af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset_all = torchvision.datasets.MNIST(\n",
    "    \"./datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "testset_all = torchvision.datasets.MNIST(\n",
    "    \"./datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae01fa2-55b9-4b41-9e59-2ac2c086c144",
   "metadata": {},
   "source": [
    "The dataset is placed in a dictionary where keys are all the unique values of the labels, and each key in the dictionary returns all the instances of the dataset relative to that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d2c1e-2998-4142-baff-f84dd1ea2f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset_all, batch_size=1)\n",
    "testloader = torch.utils.data.DataLoader(testset_all, batch_size=1)\n",
    "\n",
    "x_dict_train = {}\n",
    "x_dict_test = {}\n",
    "\n",
    "count = 0\n",
    "for x, y in trainloader:\n",
    "    if count == int(len(trainloader)):\n",
    "        break\n",
    "    count = count + 1\n",
    "    if str(y.numpy()[0]) in x_dict_train.keys():\n",
    "        x_dict_train[str(y.numpy()[0])] = torch.cat(\n",
    "            [x_dict_train[str(y.numpy()[0])], x]\n",
    "        )\n",
    "    else:\n",
    "        x_dict_train[str(y.numpy()[0])] = x\n",
    "\n",
    "count = 0\n",
    "for x, y in testloader:\n",
    "    if count == int(len(testloader)):\n",
    "        break\n",
    "    count = count + 1\n",
    "\n",
    "    if str(y.numpy()[0]) in x_dict_test.keys():\n",
    "        x_dict_test[str(y.numpy()[0])] = torch.cat([x_dict_test[str(y.numpy()[0])], x])\n",
    "    else:\n",
    "        x_dict_test[str(y.numpy()[0])] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcfe2f-fd4d-4977-8bca-80f0fd7405ac",
   "metadata": {},
   "source": [
    "We select an out-of-distribution value (ood) and build datasets (train and test) that do not contain the ood value - 'trainset' - 'testset', and a dataset that contains only ood values - 'oodset'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b41ea-3c7b-481f-b005-84e3cadb5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(ood, x_dict_train, x_dict_test):\n",
    "    trainset_x = torch.tensor([])\n",
    "    trainset_y = torch.tensor([])\n",
    "    testset_x = torch.tensor([])\n",
    "    testset_y = torch.tensor([])\n",
    "    oodset = torch.tensor([])\n",
    "\n",
    "    for key in x_dict_train.keys():\n",
    "        if key != str(ood):\n",
    "            trainset_x = torch.cat([trainset_x, x_dict_train[key]])\n",
    "            trainset_y = torch.cat(\n",
    "                [trainset_y, float(key) * torch.ones([len(x_dict_train[key])])]\n",
    "            )\n",
    "        else:\n",
    "            oodset_x = torch.cat([oodset, x_dict_train[key]])\n",
    "\n",
    "    for key in x_dict_train.keys():\n",
    "        if key != str(ood):\n",
    "            testset_x = torch.cat([testset_x, x_dict_test[key]])\n",
    "            testset_y = torch.cat(\n",
    "                [testset_y, float(key) * torch.ones([len(x_dict_test[key])])]\n",
    "            )\n",
    "        else:\n",
    "            oodset_x = torch.cat([oodset, x_dict_test[key]])\n",
    "\n",
    "    trainset = torch.utils.data.TensorDataset(trainset_x, trainset_y.long())\n",
    "    testset = torch.utils.data.TensorDataset(testset_x, testset_y.long())\n",
    "    oodset = torch.utils.data.TensorDataset(oodset_x, ood * torch.ones([len(oodset_x)]))\n",
    "\n",
    "    return trainset, testset, oodset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e5ec-07af-4a7c-9dd6-b94155c68023",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood = 2\n",
    "trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a209f2a-561c-47d3-ac90-8e9b02de9ca2",
   "metadata": {},
   "source": [
    "Here, we can visualize the composition of the sets built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708491ae-261c-4956-96ba-df41ffafe10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 20\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 5))\n",
    "\n",
    "loader = torch.utils.data.DataLoader(trainset, batch_size=nrow, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[0].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[0].set_title(\"train set\")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(testset, batch_size=nrow, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[1].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[1].set_title(\"test set\")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(oodset, batch_size=nrow, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[2].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[2].set_title(\"ood set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98fc68-9391-4223-a8f6-9f54122f2e88",
   "metadata": {},
   "source": [
    "We can see above that the train set and test set do not contain any ood values, while the ood set contains only ood values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7258a51-3b42-41b0-8112-60c9feebffb1",
   "metadata": {},
   "source": [
    "Next, we compute uncertainties on the prediction of a neural network to predict the label of an input image. We use a dataset where a specific out-of-distribution value is removed. Then we test uncertainties on a test set and on a ood set that contains only out-of-distribution values.\n",
    "Uncertainties are computed using the three different methods desctibed in the paper i.e. the inference method, the mc-dropout method and the ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923056a-9273-4df5-b5e3-928483220ff7",
   "metadata": {},
   "source": [
    "Let's train some neural networs. Several neural networks are required to be trained because the ensemble method needs different independently trained model to quantify uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598e50-d06a-453e-8f67-4afa92343be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-distribution value excluded from the training set\n",
    "ood = 0\n",
    "\n",
    "# network architectures - here two layers with 1024 nodes each\n",
    "layers_nodes = [1024, 1024]\n",
    "\n",
    "# early stopping parameter\n",
    "accuracy_target = 0.96\n",
    "\n",
    "# percentiles used by the inference methods\n",
    "q = (0.1, 50)\n",
    "\n",
    "# number of models used by the mc-dropout method\n",
    "n_models_mcdropout = 100\n",
    "\n",
    "# number of models used by the ensemble method - thus number of models to be trained\n",
    "n_models_ensemble = 10\n",
    "\n",
    "# dropout ratio used during training and during evaluation in the mc-dropout method\n",
    "p = 0.5\n",
    "\n",
    "trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for n in range(n_models_ensemble):\n",
    "\n",
    "    classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "    trained = train_classifier(\n",
    "        device, classifier, trainset, accuracy_target=accuracy_target\n",
    "    )\n",
    "    while trained == False:\n",
    "        classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "        trained = train_classifier(\n",
    "            device, classifier, trainset, accuracy_target=accuracy_target\n",
    "        )\n",
    "    classifiers.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df3823-41c0-4fa8-9741-02bb61bed94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = torch.utils.data.DataLoader(testset, batch_size=len(testset))\n",
    "x_test, y_test = next(iter(loader_test))\n",
    "y_test = y_test.numpy()\n",
    "loader_ood = torch.utils.data.DataLoader(oodset, batch_size=len(oodset))\n",
    "x_ood, _ = next(iter(loader_ood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5c7f3-c7da-480c-9c5d-9a2d323e3ebc",
   "metadata": {},
   "source": [
    "The inference and mc-dropout methods require only one model. We use the same model for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56dc60-9162-4d8e-9b8d-7f4e99d1cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifiers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5a5d8-4df4-4612-9555-3c804680028c",
   "metadata": {},
   "source": [
    "### Inference method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc28422-beef-41d1-ad0d-d5f639212de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'get_percentiles_inference' takes the model trained, the percentiles,\n",
    "#  and the training set as input, and it returns all the parameters required to compute uncertainties.\n",
    "percentiles, mean, cov, scale_mean, scale_std = get_percentiles_inference(\n",
    "    classifier, x_dict_train, ood, q\n",
    ")\n",
    "\n",
    "# 'get_confidence_inference' gives the model prediction for an input and the uncertainty.\n",
    "prediction_test_inference, confidence_test_inference = get_confidence_inference(\n",
    "    x_test, classifier, percentiles, mean, cov, scale_mean, scale_std\n",
    ")\n",
    "\n",
    "# we split between classified and misclassified data to assess the capability of the network to detect wrong predictions.\n",
    "classified_inference = y_test == prediction_test_inference\n",
    "misclassified_inference = y_test != prediction_test_inference\n",
    "prediction_ood_inference, confidence_ood_inference = get_confidence_inference(\n",
    "    x_ood, classifier, percentiles, mean, cov, scale_mean, scale_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bfe41-32a4-4874-9d02-b5c66f2b5034",
   "metadata": {},
   "source": [
    "After selecting an acceptance threhsolds that determines which predictions are accepted or rejected, we can print the true positives (TP) rate of well classified samples, the true negatives (TN) rate of correctly rejected misclassified samples, the true negatives (TN) rate of correctly rejected out-of-distribution samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d60425-d37c-45de-83ae-d24a3fe37bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_inference = 0.5\n",
    "\n",
    "print(\n",
    "    \"True positive classified: \",\n",
    "    np.mean(confidence_test_inference[classified_inference] > acceptance_inference),\n",
    ")\n",
    "print(\n",
    "    \"True negative misclassified: \",\n",
    "    np.mean(confidence_test_inference[misclassified_inference] < acceptance_inference),\n",
    ")\n",
    "print(\"True negative ood: \", np.mean(confidence_ood_inference < acceptance_inference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b1141-b42b-4c56-b05c-d2830dcf4017",
   "metadata": {},
   "source": [
    "Below we see the histograms of the confidence quantified on the samples of the 3 different datasets. We can clearly see that the large majority of out-of-distribution and misclassified samples have low confidence, whereas well classified samples have high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430c868-027b-40d2-9dbf-403ff0490cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "\n",
    "axs[0].hist(confidence_ood_inference, bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel(\"Confidence\")\n",
    "axs[0].set_ylabel(\"Normalized Counts\")\n",
    "axs[0].set_title(\"Out-of-distribution\")\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend([\"Inference\"])\n",
    "\n",
    "axs[1].hist(\n",
    "    confidence_test_inference[misclassified_inference],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[1].set_xlabel(\"Confidence\")\n",
    "axs[1].set_title(\"Misclassified\")\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend([\"Inference\"])\n",
    "\n",
    "axs[2].hist(\n",
    "    confidence_test_inference[classified_inference],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[2].set_xlabel(\"Confidence\")\n",
    "axs[2].set_title(\"Classified\")\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend([\"Inference\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0ff1d-c216-4042-9280-6c2696886b81",
   "metadata": {},
   "source": [
    "Below we repeat the same analysis as above for the MC-dropout and ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57214ee7-8ba0-48af-be29-560ab3089071",
   "metadata": {},
   "source": [
    "### MC-dropout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274ce46-4e3b-43a6-9559-3b7f92278411",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_mcdropout, confidence_test_mcdropout = get_confidence_mcdropout(\n",
    "    x_test, classifier, n_models_mcdropout\n",
    ")\n",
    "classified_mcdropout = y_test == prediction_test_mcdropout\n",
    "misclassified_mcdropout = y_test != prediction_test_mcdropout\n",
    "prediction_ood_mcdropout, confidence_ood_mcdropout = get_confidence_mcdropout(\n",
    "    x_ood, classifier, n_models_mcdropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0653e6f-bf12-4cfe-9938-5767fd91895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_mcdropout = 0.99\n",
    "\n",
    "print(\n",
    "    \"True positive classified: \",\n",
    "    np.mean(confidence_test_mcdropout[classified_mcdropout] > acceptance_mcdropout),\n",
    ")\n",
    "print(\n",
    "    \"True negative misclassified: \",\n",
    "    np.mean(confidence_test_mcdropout[misclassified_mcdropout] < acceptance_mcdropout),\n",
    ")\n",
    "print(\"True negative ood: \", np.mean(confidence_ood_mcdropout < acceptance_mcdropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10559d4-2f30-42d3-9268-31cba67a16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "axs[0].hist(confidence_ood_mcdropout, bins=bins, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel(\"Confidence\")\n",
    "axs[0].set_ylabel(\"Normalized Counts\")\n",
    "axs[0].set_title(\"Out-of-distribution\")\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend([\"MC-dropout\"])\n",
    "\n",
    "axs[1].hist(\n",
    "    confidence_test_mcdropout[misclassified_mcdropout],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[1].set_xlabel(\"Confidence\")\n",
    "axs[1].set_title(\"Misclassified\")\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend([\"MC-dropout\"])\n",
    "\n",
    "axs[2].hist(\n",
    "    confidence_test_mcdropout[classified_mcdropout],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[2].set_xlabel(\"Confidence\")\n",
    "axs[2].set_title(\"Classified\")\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend([\"MC-dropout\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b85a0-167c-478f-a740-383793c630a0",
   "metadata": {},
   "source": [
    "### Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8277aea-476c-4623-b522-982359a1162f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_test_ensemble, confidence_test_ensemble = get_confidence_ensemble(\n",
    "    x_test, classifiers\n",
    ")\n",
    "classified_ensemble = y_test == prediction_test_ensemble\n",
    "misclassified_ensemble = y_test != prediction_test_ensemble\n",
    "prediction_ood_ensemble, confidence_ood_ensemble = get_confidence_ensemble(\n",
    "    x_ood, classifiers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c0cd7-02b3-478c-b5b4-e1b4c994f647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acceptance_ensemble = 0.99\n",
    "\n",
    "print(\n",
    "    \"True positive classified: \",\n",
    "    np.mean(confidence_test_ensemble[classified_ensemble] > acceptance_ensemble),\n",
    ")\n",
    "print(\n",
    "    \"True negative misclassified: \",\n",
    "    np.mean(confidence_test_ensemble[misclassified_ensemble] < acceptance_ensemble),\n",
    ")\n",
    "print(\"True negative ood: \", np.mean(confidence_ood_ensemble < acceptance_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d551a-3d5d-42b0-b1b0-7ff7628a0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "axs[0].hist(confidence_ood_ensemble, bins=bins, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel(\"Confidence\")\n",
    "axs[0].set_ylabel(\"Normalized Counts\")\n",
    "axs[0].set_title(\"Out-of-distribution\")\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend([\"Ensemble\"])\n",
    "\n",
    "axs[1].hist(\n",
    "    confidence_test_ensemble[misclassified_ensemble],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[1].set_xlabel(\"Confidence\")\n",
    "axs[1].set_title(\"Misclassified\")\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend([\"Ensemble\"])\n",
    "\n",
    "axs[2].hist(\n",
    "    confidence_test_ensemble[classified_ensemble],\n",
    "    bins=bins,\n",
    "    width=0.1,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    ")\n",
    "axs[2].set_xlabel(\"Confidence\")\n",
    "axs[2].set_title(\"Classified\")\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend([\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c874af-fcdf-43f9-8f90-519d9b43429f",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8332e2c-b643-42f0-8755-6e51331f659f",
   "metadata": {},
   "source": [
    "Below, we perform the experiment that has been used to compile Table 2 in the manuscript.\n",
    "\n",
    "In the experiment, all possible labels are removed one-by-one  to assemble a diffent dataset at each iteration. The three uncertainty quantification methods are then trained and tested on the assembled data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae6deb-5f3a-4a16-b1d9-b57b52994885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment(\n",
    "    layers_nodes,\n",
    "    accuracy_target,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    p,\n",
    "    n_models_mcdropout,\n",
    "    n_models_ensemble,\n",
    "    acceptance_inference,\n",
    "    acceptance_mcdropout,\n",
    "    acceptance_ensemble,\n",
    "):\n",
    "\n",
    "    tp_classified_inference = {}\n",
    "    tn_misclassified_inference = {}\n",
    "    tn_ood_inference = {}\n",
    "    for q in q_values:\n",
    "        tp_classified_inference[q] = []\n",
    "        tn_misclassified_inference[q] = []\n",
    "        tn_ood_inference[q] = []\n",
    "\n",
    "    tp_classified_mcdropout = []\n",
    "    tn_misclassified_mcdropout = []\n",
    "    tn_ood_mcdropout = []\n",
    "\n",
    "    tp_classified_ensemble = []\n",
    "    tn_misclassified_ensemble = []\n",
    "    tn_ood_ensemble = []\n",
    "\n",
    "    print(\"Experiment being performed...\")\n",
    "    for ood in range(10):\n",
    "\n",
    "        print(ood + 1, \"/ 10\")\n",
    "\n",
    "        trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)\n",
    "        classifiers = []\n",
    "\n",
    "        for n in range(n_models_ensemble):\n",
    "\n",
    "            classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "            trained = train_classifier(\n",
    "                device,\n",
    "                classifier,\n",
    "                trainset,\n",
    "                accuracy_target=accuracy_target,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "            while trained == False:\n",
    "                classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "                trained = train_classifier(\n",
    "                    device,\n",
    "                    classifier,\n",
    "                    trainset,\n",
    "                    accuracy_target=accuracy_target,\n",
    "                    batch_size=batch_size,\n",
    "                )\n",
    "            classifiers.append(classifier)\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(testset, batch_size=len(testset))\n",
    "        x_test, y_test = next(iter(loader))\n",
    "        y_test = y_test.cpu().numpy()\n",
    "        loader = torch.utils.data.DataLoader(oodset, batch_size=len(oodset))\n",
    "        x_ood, _ = next(iter(loader))\n",
    "\n",
    "        for q in q_values:\n",
    "            percentiles, mean, cov, scale_mean, scale_std = get_percentiles_inference(\n",
    "                classifiers[0], x_dict_train, ood, q\n",
    "            )\n",
    "            (\n",
    "                prediction_test_inference,\n",
    "                confidence_test_inference,\n",
    "            ) = get_confidence_inference(\n",
    "                x_test, classifiers[0], percentiles, mean, cov, scale_mean, scale_std\n",
    "            )\n",
    "            classified_inference = y_test == prediction_test_inference\n",
    "            misclassified_inference = y_test != prediction_test_inference\n",
    "            (\n",
    "                prediction_ood_inference,\n",
    "                confidence_ood_inference,\n",
    "            ) = get_confidence_inference(\n",
    "                x_ood, classifiers[0], percentiles, mean, cov, scale_mean, scale_std\n",
    "            )\n",
    "\n",
    "            tp_classified_inference[q].append(\n",
    "                np.mean(\n",
    "                    confidence_test_inference[classified_inference]\n",
    "                    > acceptance_inference\n",
    "                )\n",
    "            )\n",
    "            tn_misclassified_inference[q].append(\n",
    "                np.mean(\n",
    "                    confidence_test_inference[misclassified_inference]\n",
    "                    < acceptance_inference\n",
    "                )\n",
    "            )\n",
    "            tn_ood_inference[q].append(\n",
    "                np.mean(confidence_ood_inference < acceptance_inference)\n",
    "            )\n",
    "\n",
    "        prediction_test_mcdropout, confidence_test_mcdropout = get_confidence_mcdropout(\n",
    "            x_test, classifiers[0], n_models_mcdropout\n",
    "        )\n",
    "        classified_mcdropout = y_test == prediction_test_mcdropout\n",
    "        misclassified_mcdropout = y_test != prediction_test_mcdropout\n",
    "        prediction_ood_mcdropout, confidence_ood_mcdropout = get_confidence_mcdropout(\n",
    "            x_ood, classifiers[0], n_models_mcdropout\n",
    "        )\n",
    "\n",
    "        tp_classified_mcdropout.append(\n",
    "            np.mean(\n",
    "                confidence_test_mcdropout[classified_mcdropout] > acceptance_mcdropout\n",
    "            )\n",
    "        )\n",
    "        tn_misclassified_mcdropout.append(\n",
    "            np.mean(\n",
    "                confidence_test_mcdropout[misclassified_mcdropout]\n",
    "                < acceptance_mcdropout\n",
    "            )\n",
    "        )\n",
    "        tn_ood_mcdropout.append(\n",
    "            np.mean(confidence_ood_mcdropout < acceptance_mcdropout)\n",
    "        )\n",
    "\n",
    "        prediction_test_ensemble, confidence_test_ensemble = get_confidence_ensemble(\n",
    "            x_test, classifiers\n",
    "        )\n",
    "        classified_ensemble = y_test == prediction_test_ensemble\n",
    "        misclassified_ensemble = y_test != prediction_test_ensemble\n",
    "        prediction_ood_ensemble, confidence_ood_ensemble = get_confidence_ensemble(\n",
    "            x_ood, classifiers\n",
    "        )\n",
    "\n",
    "        tp_classified_ensemble.append(\n",
    "            np.mean(confidence_test_ensemble[classified_ensemble] > acceptance_ensemble)\n",
    "        )\n",
    "        tn_misclassified_ensemble.append(\n",
    "            np.mean(\n",
    "                confidence_test_ensemble[misclassified_ensemble] < acceptance_ensemble\n",
    "            )\n",
    "        )\n",
    "        tn_ood_ensemble.append(np.mean(confidence_ood_ensemble < acceptance_ensemble))\n",
    "\n",
    "    for q in q_values:\n",
    "        print(\"\")\n",
    "        print(\"Inference method: \")\n",
    "        print(\"-q: \", q)\n",
    "        print(\n",
    "            \"TP classified: \",\n",
    "            np.around(np.mean(tp_classified_inference[q]), 3),\n",
    "            np.around(np.std(tp_classified_inference[q]), 3),\n",
    "        )\n",
    "        print(\n",
    "            \"TN misclassified: \",\n",
    "            np.around(np.mean(tn_misclassified_inference[q]), 3),\n",
    "            np.around(np.std(tn_misclassified_inference[q]), 3),\n",
    "        )\n",
    "        print(\n",
    "            \"TN ood: \",\n",
    "            np.around(np.mean(tn_ood_inference[q]), 3),\n",
    "            np.around(np.std(tn_ood_inference[q]), 3),\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"MC-dropout method: \")\n",
    "    print(\n",
    "        \"TP classified: \",\n",
    "        np.around(np.mean(tp_classified_mcdropout), 3),\n",
    "        np.around(np.std(tp_classified_mcdropout), 3),\n",
    "    )\n",
    "    print(\n",
    "        \"TN misclassified: \",\n",
    "        np.around(np.mean(tn_misclassified_mcdropout), 3),\n",
    "        np.around(np.std(tn_misclassified_mcdropout), 3),\n",
    "    )\n",
    "    print(\n",
    "        \"TN ood: \",\n",
    "        np.around(np.mean(tn_ood_mcdropout), 3),\n",
    "        np.around(np.std(tn_ood_mcdropout), 3),\n",
    "    )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Ensemble method: \")\n",
    "    print(\n",
    "        \"TP classified: \",\n",
    "        np.around(np.mean(tp_classified_ensemble), 3),\n",
    "        np.around(np.std(tp_classified_ensemble), 3),\n",
    "    )\n",
    "    print(\n",
    "        \"TN misclassified: \",\n",
    "        np.around(np.mean(tn_misclassified_ensemble), 3),\n",
    "        np.around(np.std(tn_misclassified_ensemble), 3),\n",
    "    )\n",
    "    print(\n",
    "        \"TN ood: \",\n",
    "        np.around(np.mean(tn_ood_ensemble), 3),\n",
    "        np.around(np.std(tn_ood_ensemble), 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66c351-343a-49af-b8a4-274f6580df14",
   "metadata": {},
   "source": [
    "The experiment is conducted below with different network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8778cc-b7b0-4271-bebd-c7428b5a6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_target = 0.96\n",
    "batch_size = 16\n",
    "\n",
    "n_models_mcdropout = 100\n",
    "n_models_ensemble = 2\n",
    "\n",
    "acceptance_inference = 0.5\n",
    "acceptance_mcdropout = 0.99\n",
    "acceptance_ensemble = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7e7cd-f1b9-469e-9bc3-eb691657c6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(0.01, 1), (0.1, 50), (3, 90)]\n",
    "layers_nodes = [1024, 1024]\n",
    "p = 0.2\n",
    "\n",
    "perform_experiment(\n",
    "    layers_nodes=layers_nodes,\n",
    "    accuracy_target=accuracy_target,\n",
    "    batch_size=batch_size,\n",
    "    p=p,\n",
    "    n_models_mcdropout=n_models_mcdropout,\n",
    "    n_models_ensemble=n_models_ensemble,\n",
    "    acceptance_inference=acceptance_inference,\n",
    "    acceptance_mcdropout=acceptance_mcdropout,\n",
    "    acceptance_ensemble=acceptance_ensemble,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb54fc-6c0f-4b82-b1a9-a9f3d7b0bc04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(0.01, 1), (0.1, 50), (3, 90)]\n",
    "layers_nodes = [1024, 1024]\n",
    "p = 0.5\n",
    "\n",
    "perform_experiment(\n",
    "    layers_nodes=layers_nodes,\n",
    "    accuracy_target=accuracy_target,\n",
    "    batch_size=batch_size,\n",
    "    p=p,\n",
    "    n_models_mcdropout=n_models_mcdropout,\n",
    "    n_models_ensemble=n_models_ensemble,\n",
    "    acceptance_inference=acceptance_inference,\n",
    "    acceptance_mcdropout=acceptance_mcdropout,\n",
    "    acceptance_ensemble=acceptance_ensemble,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f1824-403b-4820-b844-49332e29869f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(2, 10), (3, 50), (7, 90)]\n",
    "layers_nodes = [256, 256, 256, 256]\n",
    "p = 0.1\n",
    "\n",
    "perform_experiment(\n",
    "    layers_nodes=layers_nodes,\n",
    "    accuracy_target=accuracy_target,\n",
    "    batch_size=batch_size,\n",
    "    p=p,\n",
    "    n_models_mcdropout=n_models_mcdropout,\n",
    "    n_models_ensemble=n_models_ensemble,\n",
    "    acceptance_inference=acceptance_inference,\n",
    "    acceptance_mcdropout=acceptance_mcdropout,\n",
    "    acceptance_ensemble=acceptance_ensemble,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4a328-9793-492d-996d-2c272a838549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(2, 10), (3, 50), (7, 90)]\n",
    "layers_nodes = [256, 256, 256, 256]\n",
    "p = 0.25\n",
    "\n",
    "perform_experiment(\n",
    "    layers_nodes=layers_nodes,\n",
    "    accuracy_target=accuracy_target,\n",
    "    batch_size=batch_size,\n",
    "    p=p,\n",
    "    n_models_mcdropout=n_models_mcdropout,\n",
    "    n_models_ensemble=n_models_ensemble,\n",
    "    acceptance_inference=acceptance_inference,\n",
    "    acceptance_mcdropout=acceptance_mcdropout,\n",
    "    acceptance_ensemble=acceptance_ensemble,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
